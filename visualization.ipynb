{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20d2ead-2653-42a1-b869-d9ac021fa92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "\n",
    "gat_path = ''\n",
    "\n",
    "gat = torch_geometric.nn.GAT(-1, 20, num_layers=2, out_channels=1, dropout=0.5)\n",
    "gat.load_state_dict(torch.load(gat_path))\n",
    "gat.eval()\n",
    "\n",
    "gcn_path = ''\n",
    "\n",
    "gcn = torch_geometric.nn.GCN(-1, 10, num_layers=2, out_channels=1, dropout=0.5)\n",
    "gcn.load_state_dict(torch.load(gcn_path))\n",
    "gcn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331e689a-ec86-4255-b865-844464f91737",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd55d2d4-6c4f-4ee7-a768-7f94d0226a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to calculate loss on test\n",
    "\n",
    "def predict(model, batch, device):\n",
    "    \"\"\" Predice node-wise probabilities of being a coordinating atom given a batch. \"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    batch = batch.to(device)\n",
    "    \n",
    "    out_logits = model(x=batch.x, edge_index=batch.edge_index.to(torch.int64), edge_attr=batch.edge_attr)\n",
    "    out_probs = torch.nn.functional.sigmoid(out_logits)\n",
    "    return out_probs\n",
    "\n",
    "def compute_batch_loss(preds: torch.Tensor, labels: torch.Tensor, inds: torch.Tensor):\n",
    "    \"\"\" \n",
    "    Computes a cross-entropy loss for each atom.\n",
    "    Then, computes the mean of that loss for each ligand, and then across all ligands in the batch\n",
    "    Parameters\n",
    "    ----------\n",
    "    preds : torch.Tensor (N,1)\n",
    "        Atom-wise predicted logits for not-being or being a coordinating atom\n",
    "    labels : torch.Tensor (N,1)\n",
    "        Atom-wise labels for whether it isn't or is a coordinating atom\n",
    "    inds : torch.Tensor (batch_size+1)\n",
    "        The indices defining the ligands within each batch. Uses the batch.ptr generated by the torch_geometric dataloader.\n",
    "    Return\n",
    "    ------\n",
    "    torch.Tensor (1,)\n",
    "        Mean batch loss\n",
    "    \"\"\"\n",
    "    # this is (N,2) for some reason\n",
    "    loss_per_node = torch.nn.functional.binary_cross_entropy(preds, labels, reduction='none',\n",
    "                                                             weight=torch.Tensor([1]).to(0))\n",
    "    # Compute the mean cross-entropy across each individual graph, then the mean across the entire batch\n",
    "    # graph_sizes = torch.diff(inds)\n",
    "    # segment_ids = torch.repeat_interleave(torch.arange(len(graph_sizes), device=preds.device), graph_sizes)\n",
    "    # graph_losses = torch_scatter.scatter_mean(loss_per_node, segment_ids, dim=0)\n",
    "    # return graph_losses.mean()\n",
    "    \n",
    "    # Experimenting with averaging negative and positive losses\n",
    "    # Note: this does not average over graphs\n",
    "    # neg_loss = loss_per_node[labels[:,0].nonzero()]\n",
    "    # pos_loss = loss_per_node[labels[:,1].nonzero()]\n",
    "    # return neg_loss.mean() + pos_loss.mean()\n",
    "    \n",
    "    ## Average negative and positive losses separately per graph\n",
    "    graph_sizes = torch.diff(inds)\n",
    "    # Get how many ones/zeros are in each individual graph\n",
    "    num_ones_per_graph = torch.Tensor([len(labels[inds[i-1]:inds[i]].nonzero()) for i in range(1,len(inds))],\n",
    "                                     ).to(torch.long)\n",
    "    num_zeros_per_graph = torch.Tensor([len(torch.where(labels[inds[i-1]:inds[i]]==0)[0]) for i in range(1,len(inds))],\n",
    "                                     ).to(torch.long)\n",
    "    ones_seg_ids = torch.repeat_interleave(torch.arange(len(num_ones_per_graph)), num_ones_per_graph).to(preds.device)\n",
    "    zeros_seg_ids = torch.repeat_interleave(torch.arange(len(num_zeros_per_graph)), num_zeros_per_graph).to(preds.device)\n",
    "    # compute mean loss for each pos/neg for each graph\n",
    "    pos_loss = torch_scatter.scatter_mean(loss_per_node[labels.flatten().nonzero().flatten()], ones_seg_ids, dim=0)\n",
    "    neg_loss = torch_scatter.scatter_mean(loss_per_node[torch.where(labels==0)[0]], zeros_seg_ids, dim=0)\n",
    "    combined_loss_per_graph = pos_loss + neg_loss # element-wise for each graph\n",
    "\n",
    "    # pred_num_one = torch_scatter.scatter_add(loss_per_node[labels.flatten().nonzero().flatten()], ones_seg_ids, dim=0)\n",
    "    # pred_num_zero = torch_scatter.scatter_add(loss_per_node[torch.where(labels==0)[0]], zeros_seg_ids, dim=0)\n",
    "    \n",
    "    return (combined_loss_per_graph.mean())\n",
    "            # + 0.5*torch.mean(torch.square(pred_num_one/denticities - 1))\n",
    "            # + 0.01*torch.mean(torch.square(pred_num_zero/(natoms-denticities))))\n",
    "\n",
    "test_data = torch.load('data/test_dataset.pt')\n",
    "test_loader = DataLoader(test_data, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011366b2-c497-4e7b-ada4-deb712796565",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "pred_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        batch.to(device)\n",
    "        out_probs = 1-batch.y.to(torch.float64).to(device)\n",
    "        loss = compute_batch_loss(out_probs, batch.y.to(torch.float64), batch.ptr)\n",
    "        pred_opp_loss += loss.item()\n",
    "pred_loss = pred_loss / (i+1)\n",
    "\n",
    "pred_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9fb739-4f43-477c-920a-a1068ec7bab1",
   "metadata": {},
   "source": [
    "# Denticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c5406-11ff-40c6-95d4-f071a8de549d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af0494e4-6672-4c25-afad-93cd45a42284",
   "metadata": {},
   "source": [
    "# Identity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
